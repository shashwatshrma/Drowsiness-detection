{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6f1d8a-475f-41d9-8ae5-e6becde4bee3",
   "metadata": {},
   "source": [
    "## Making our data generators\n",
    "We will use ImageDataGenerator to implement data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95e00e43-39b1-43db-957d-d2374964bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23a7bd3d-3e8f-4da3-a0c7-facd8261676b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51200 images belonging to 2 classes.\n",
      "Found 12800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   validation_split = 0.2)\n",
    "train_data = train_datagen.flow_from_directory('./prepared_data/train_data/', target_size = (80,80), batch_size = 8, class_mode = 'binary', subset = 'training')\n",
    "validation_data = train_datagen.flow_from_directory('./prepared_data/train_data/', target_size = (80,80), batch_size = 8, class_mode = 'binary', subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21a3c87f-4a5a-4399-b9e4-47680149ca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20898 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_data = test_datagen.flow_from_directory('./prepared_data/test_data', target_size = (80,80), batch_size = 8, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3a37c-7307-4600-bd20-554edb81abdd",
   "metadata": {},
   "source": [
    "## Making our model\n",
    "We will use the concept of Transfer Learning and use the Inception model as the base model to make our CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0eb2fa3e-ac0c-4ab2-b0f7-fe4d3deb9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dropout, Input, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6430a2ba-285a-4740-975d-bfd3a002aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will make our own dense layers so we do not need the final dense layers of Inception\n",
    "base_model = InceptionV3(include_top = False, weights = 'imagenet', input_tensor = Input(shape = (80,80,3)))\n",
    "head_model = base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb533d14-b372-4242-ab1f-03cb6ab204eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need to train layers from InceptionV3\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0bb5aac-a632-4f33-9d1a-4a40f081be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the head model\n",
    "head_model=Flatten()(head_model) # flatten the incoming image data to a 1d vector\n",
    "head_model=Dense(64,activation='relu')(head_model)\n",
    "head_model=Dropout(0.2)(head_model) # avoids overfitting\n",
    "head_model=Dense(1,activation='sigmoid')(head_model) # gives the class\n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = head_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853af32-1f0c-487c-91ba-dcd117e10889",
   "metadata": {},
   "source": [
    "## Training our head model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3147cf74-f0a3-4069-a7ad-002cace68049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "checkpoint = ModelCheckpoint('./model checkpoint/model.keras', monitor = 'val_loss', save_best_only = True)\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', patience = 7, restore_best_weights = True)\n",
    "learning_rate = ReduceLROnPlateau(monitor = 'val_loss', patience = 3)\n",
    "callbacks = [checkpoint, earlystop, learning_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cbb8909-e1df-4cc7-ab77-fd7bda32e1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n",
      "51200\n",
      "1600\n",
      "12800\n"
     ]
    }
   ],
   "source": [
    "batch_size = 80\n",
    "print(train_data.samples // batch_size * 10)\n",
    "print(train_data.samples)\n",
    "print(validation_data.samples // batch_size * 10)\n",
    "print(validation_data.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "526e4c26-3fce-487e-a5d3-fbc03bb2ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 131ms/step - accuracy: 0.8757 - loss: 0.3038 - val_accuracy: 0.8711 - val_loss: 0.2865 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 104ms/step - accuracy: 0.9230 - loss: 0.1975 - val_accuracy: 0.8484 - val_loss: 0.3281 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 79ms/step - accuracy: 0.9212 - loss: 0.1927 - val_accuracy: 0.8797 - val_loss: 0.2795 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 60ms/step - accuracy: 0.9289 - loss: 0.1835 - val_accuracy: 0.9164 - val_loss: 0.2642 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.9285 - loss: 0.1801 - val_accuracy: 0.8813 - val_loss: 0.2651 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 57ms/step - accuracy: 0.9329 - loss: 0.1701 - val_accuracy: 0.8875 - val_loss: 0.2660 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.9286 - loss: 0.1776 - val_accuracy: 0.9117 - val_loss: 0.2130 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 53ms/step - accuracy: 0.9408 - loss: 0.1560 - val_accuracy: 0.8859 - val_loss: 0.2889 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.9372 - loss: 0.1607 - val_accuracy: 0.8984 - val_loss: 0.2701 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 52ms/step - accuracy: 0.9431 - loss: 0.1538 - val_accuracy: 0.9031 - val_loss: 0.2491 - learning_rate: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f4980fa790>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(train_data,\n",
    "          steps_per_epoch = train_data.samples // batch_size,\n",
    "          validation_data = validation_data,\n",
    "          validation_steps = validation_data.samples // batch_size,\n",
    "          callbacks = callbacks, \n",
    "          epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097719d2-292d-45d5-b312-68e82bf82d7a",
   "metadata": {},
   "source": [
    "## Evaluating our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d5ff490-af2e-46fc-9f8c-88ca9b6c36b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6400/6400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 43ms/step - accuracy: 0.9343 - loss: 0.1642\n",
      "0.9344335794448853\n",
      "0.16515152156352997\n"
     ]
    }
   ],
   "source": [
    "loss_train, acc_train = model.evaluate(train_data)\n",
    "print(acc_train)\n",
    "print(loss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "076190cd-9d69-4c58-aa68-5dab0e4bbdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 43ms/step - accuracy: 0.9066 - loss: 0.2255\n",
      "0.8993750214576721\n",
      "0.2423509806394577\n"
     ]
    }
   ],
   "source": [
    "loss_val, acc_val = model.evaluate(validation_data)\n",
    "print(acc_val)\n",
    "print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9479db0-9511-49bc-b78c-afaad4fc2b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2613/2613\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 41ms/step - accuracy: 0.9443 - loss: 0.1476\n",
      "0.9432960152626038\n",
      "0.14809730648994446\n"
     ]
    }
   ],
   "source": [
    "loss_test, acc_test = model.evaluate(test_data)\n",
    "print(acc_test)\n",
    "print(loss_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
